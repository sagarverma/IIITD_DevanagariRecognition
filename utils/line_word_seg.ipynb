{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_DIR = '../dataset/nai_duniya/'\n",
    "pdfs = os.listdir(PDF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_no = 1\n",
    "for pdf in pdfs:\n",
    "    img = convert_from_path(PDF_DIR + pdf)\n",
    "    img = img.pop()\n",
    "    img = np.asarray(img)\n",
    "    \n",
    "    \"\"\"\n",
    "    pdf = pdfplumber.open(PDF_DIR + pdf)\n",
    "    first_page = pdf.pages[0]\n",
    "    words = first_page.extract_words()\n",
    "    im = first_page.to_image(200)\n",
    "    \n",
    "    nwords = []\n",
    "    bbox = []\n",
    "    for word in words:\n",
    "        xmin = word['x0']\n",
    "        xmax = word['x1']\n",
    "        ymin = word['top']\n",
    "        ymax = word['bottom']\n",
    "\n",
    "        if not ((xmax-xmin) > 130 and (ymax-ymin) < 50): \n",
    "            xmax *= im.scale \n",
    "            xmin *= im.scale \n",
    "            ymax *= im.scale \n",
    "            ymin *= im.scale \n",
    "\n",
    "            bbox.append([xmin, ymin, xmax, ymax])\n",
    "    \"\"\"        \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite('../dataset/nai_duniya_png/' + str(img_no).zfill(2) + '.png', img)\n",
    "    #np.save('../dataset/words_localized/' + str(img_no).zfill(2) + '.npy', bbox)\n",
    "    \n",
    "    img_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = os.listdir('../dataset/words_localized/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgn in imgs:\n",
    "    if 'png' in imgn:\n",
    "        img = cv2.imread('../dataset/words_localized/' + imgn)\n",
    "        npy = np.load('../dataset/words_localized/' + imgn[:-4] + '.npy')\n",
    "        \n",
    "        for bb in npy:\n",
    "            cv2.rectangle(img, (bb[0], bb[1]), (bb[2], bb[3]), (0,255,0), 1)\n",
    "            \n",
    "        cv2.imwrite('../dataset/words_localized/' + 'bbox_' + imgn, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = os.listdir('../dataset/words_localized/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimgs = []\n",
    "for img in imgs:\n",
    "    if 'png' in img and 'bbox' not in img:\n",
    "        nimgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../dataset/words_localized/' + nimgs[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test1.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters, segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = filters.threshold_otsu(img)\n",
    "mask = img < val\n",
    "clean_border = segmentation.clear_border(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('clean_border.png', (1 - clean_border) * 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tesserocr import PyTessBaseAPI, RIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 textline image components.\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('clean_border.png')\n",
    "with PyTessBaseAPI() as api:\n",
    "    api.SetImage(image)\n",
    "    boxes = api.GetComponentImages(RIL.WORD, True)\n",
    "    print 'Found {} textline image components.'.format(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('clean_border.png')\n",
    "for bb in boxes:\n",
    "    cv2.rectangle(img, (bb[1]['x'],bb[1]['y']), (bb[1]['x']+bb[1]['w'],bb[1]['y']+bb[1]['h']), (0,255,0), 1)\n",
    "cv2.imwrite('bb_detected_pdf.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get the given level kind of components (block, textline, word etc.) as a\n",
       "list of image, box bounds {x, y, width, height} tuples in reading order.\n",
       "\n",
       "Can be called before or after :meth:`Recognize`.\n",
       "\n",
       "Args:\n",
       "    level (int): Iterator level. See :class:`RIL`.\n",
       "    text_only (bool): If ``True``, then only text components are returned.\n",
       "\n",
       "Kwargs:\n",
       "    raw_image (bool): If ``True``, then portions of the original image are extracted\n",
       "        instead of the thresholded image and padded with `raw_padding`. Defaults to\n",
       "        ``False``.\n",
       "    raw_padding (int): Image padding pixels. Defaults to 0.\n",
       "    blockids (bool): If ``True``, the block-id of each component is also included\n",
       "        in the returned tuples (`None` otherwise). Defaults to ``True``.\n",
       "    paraids (bool): If ``True``, the paragraph-id of each component with its block\n",
       "        is also included in the returned tuples.\n",
       "\n",
       "Returns:\n",
       "    list: List of tuples containing the following values respectively::\n",
       "\n",
       "        image (:class:`PIL.Image`): Image object.\n",
       "        bounding box (dict): dict with x, y, w, h keys.\n",
       "        block id (int): textline block id (if blockids is ``True``). ``None`` otherwise.\n",
       "        paragraph id (int): textline paragraph id within its block (if paraids is True).\n",
       "            ``None`` otherwise.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.GetComponentImages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
